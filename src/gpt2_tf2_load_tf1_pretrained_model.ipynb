{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:40:45.804293Z",
     "start_time": "2021-05-14T03:40:43.482109Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:40:45.808880Z",
     "start_time": "2021-05-14T03:40:45.806125Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:40:46.481399Z",
     "start_time": "2021-05-14T03:40:45.812237Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:40:46.584490Z",
     "start_time": "2021-05-14T03:40:46.484230Z"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ROOT = './checkpoint'\n",
    "SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:02.808093Z",
     "start_time": "2021-05-14T03:41:02.703826Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = model_tf2.GPT2(model_tf2.HPARAMS['355M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:04.123232Z",
     "start_time": "2021-05-14T03:41:04.118432Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))\n",
    "# mask = model_tf2.create_look_ahead_mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:05.781109Z",
     "start_time": "2021-05-14T03:41:05.124202Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:05.807406Z",
     "start_time": "2021-05-14T03:41:05.782279Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wte (SharedEmbeddings)       multiple                  51463168  \n",
      "_________________________________________________________________\n",
      "wpe (Embedding)              multiple                  1048576   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 354,823,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:10.589917Z",
     "start_time": "2021-05-14T03:41:10.497254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 292 trainable variables.\n",
      "gpt2_tf2/wte/weight:0 (50257, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/wpe/embeddings:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/beta:0 (1024,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} trainable variables.\".format(\n",
    "    len(gpt2.trainable_variables)))\n",
    "for v in gpt2.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from TF1 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:17.210192Z",
     "start_time": "2021-05-14T03:41:17.205854Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_directory = \"../models/355M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:29.608791Z",
     "start_time": "2021-05-14T03:41:17.948952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h0/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h0/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h0/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h0/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h1/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h1/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h1/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h1/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h1/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h10/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h10/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h10/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h10/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h10/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h11/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h11/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h11/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h11/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h11/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h12/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h12/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h12/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h12/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h12/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h12/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h13/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h13/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h13/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h13/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h13/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h13/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h14/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h14/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h14/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h14/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h14/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h14/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h15/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h15/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h15/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h15/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h15/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h15/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h16/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h16/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h16/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h16/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h16/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h16/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h17/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h17/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h17/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h17/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h17/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h17/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h18/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h18/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h18/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h18/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h18/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h18/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h19/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h19/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h19/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h19/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h19/mlp/c_fc/w with shape [1, 1024, 4096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h19/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h2/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h2/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h2/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h2/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h2/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h20/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h20/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h20/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h20/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h20/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h20/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h21/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h21/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h21/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h21/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h21/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h21/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h22/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h22/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h22/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h22/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h22/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h22/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h23/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h23/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h23/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h23/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h23/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h23/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h3/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h3/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h3/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h3/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h3/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h4/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h4/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h4/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h4/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h4/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h5/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h5/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h5/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h5/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h5/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h6/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h6/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h6/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h6/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h6/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h7/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h7/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h7/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h7/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h7/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h8/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h8/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h8/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h8/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h8/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h9/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h9/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h9/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h9/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 1024, 4096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/ln_f/b with shape [1024]\n",
      "Loading TF weight model/ln_f/g with shape [1024]\n",
      "Loading TF weight model/wpe with shape [1024, 1024]\n",
      "Loading TF weight model/wte with shape [50257, 1024]\n",
      "292 vars loaded from ckpt ../models/355M\n"
     ]
    }
   ],
   "source": [
    "ckpt_vars = tf.train.list_variables(ckpt_directory)\n",
    "names = []\n",
    "tensors = []\n",
    "\n",
    "for name, shape in ckpt_vars:\n",
    "    print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    tensor = tf.train.load_variable(ckpt_directory, name)\n",
    "    names.append(str(name[6:].split(\"/\")))\n",
    "    tensors.append(tensor)\n",
    "assert len(names) == len(tensors)\n",
    "print(\"{} vars loaded from ckpt {}\".format(len(ckpt_vars), ckpt_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:29.611987Z",
     "start_time": "2021-05-14T03:41:29.610089Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_vmap = dict(zip(names, tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:30.375439Z",
     "start_time": "2021-05-14T03:41:30.371024Z"
    }
   },
   "outputs": [],
   "source": [
    "vname_mapping = {\"kernel\": \"w\", \"bias\": \"b\", \"gamma\": \"g\", \"beta\": \"b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:33.821091Z",
     "start_time": "2021-05-14T03:41:33.326390Z"
    }
   },
   "outputs": [],
   "source": [
    "for v in gpt2.trainable_variables:\n",
    "    tf2_vname = v.name[9:-2].split(\"/\")\n",
    "    if tf2_vname[0] == \"decoder\":\n",
    "        tf2_vname = tf2_vname[1:]\n",
    "    elif tf2_vname[0] == \"wte\" or tf2_vname[0] == \"wpe\":\n",
    "        tf2_vname = [tf2_vname[0]]\n",
    "    if tf2_vname[-1] in vname_mapping:\n",
    "        tf2_vname[-1] = vname_mapping[tf2_vname[-1]]\n",
    "    tf2_vvalue = np.squeeze(ckpt_vmap[str(tf2_vname)])\n",
    "    assert v.shape == tf2_vvalue.shape, \\\n",
    "        \"{} has different shape: gpt2_tf2 {} vs gpt2_tf1 {}\" \\\n",
    "        .format(v.name, str(v.shape), str(tf2_vvalue.shape))\n",
    "    v.assign(tf2_vvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:49.247038Z",
     "start_time": "2021-05-14T03:41:49.129171Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"355M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:41:50.799719Z",
     "start_time": "2021-05-14T03:41:50.793763Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:42:20.795739Z",
     "start_time": "2021-05-14T03:41:51.788216Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:42:20.800784Z",
     "start_time": "2021-05-14T03:42:20.797175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can we be friends?\\n\\nCan we become allies?\\n\\nCan we help each other?\\n\\nYou can find out more about why I feel so strongly about this topic in my blog posts, or even in my book about the relationship of science to culture.\\n\\nThanks for visiting.\\n\\n–Dr. Jennifer D. Miller, M.D.<|endoftext|>It seems like the past 24 hours have been one big mess. The Trump administration continues to do things like pull an executive order banning Americans from seven predominately Muslim countries and threatening to pull out of the Paris climate accord; while acting as if the U.S. shouldn't be part of an international deal to deal with climate change, which is why this administration has chosen the first move to pull us out of international climate negotiations. President Trump even promised to keep us out of the Paris Agreement at the end of his speech:\\n\\nWe were going to pull out of the Paris Climate Accord — stop it. We were going to negotiate out of it\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:42:54.065413Z",
     "start_time": "2021-05-14T03:42:52.623210Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2.save_weights(\"../models/355M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:05.853023Z",
     "start_time": "2021-05-14T03:43:04.618221Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:09.561347Z",
     "start_time": "2021-05-14T03:43:08.798272Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded = model_tf2.GPT2(model_tf2.HPARAMS['355M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:11.428759Z",
     "start_time": "2021-05-14T03:43:10.175180Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:12.148998Z",
     "start_time": "2021-05-14T03:43:11.432183Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2_loaded(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:18.800402Z",
     "start_time": "2021-05-14T03:43:17.845906Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded.load_weights(\"../models/355M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:19.754989Z",
     "start_time": "2021-05-14T03:43:19.714753Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wte (SharedEmbeddings)       multiple                  51463168  \n",
      "_________________________________________________________________\n",
      "wpe (Embedding)              multiple                  1048576   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 354,823,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:28.792864Z",
     "start_time": "2021-05-14T03:43:28.710388Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"355M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:43:30.870432Z",
     "start_time": "2021-05-14T03:43:30.864319Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:00.612476Z",
     "start_time": "2021-05-14T03:43:31.513194Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:00.623087Z",
     "start_time": "2021-05-14T03:44:00.614334Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we be friends? \"We will find something for anyone else,\" one woman is saying in a post that has been shared more than 1,000 times.\\n\\nOne reader shared a post from her mother, who said the police had done everything they set out to do, and it was going to take at least six months before she found out what had happened. Another asked for information on how the police \"could not get justice for her family and have been unable to obtain legal representation because of the ongoing legal battle.\"\\n\\nThe city\\'s website listed a slew of cases to help find the truth. That included a Facebook post from one of the victims of the shooting that described how she had been on the sidewalk. \"At 7 AM, we found her,\" reads the description. \"All I could think about was the pain that my daughter was experiencing and the time I had left in her life.\"\\n\\nThe post has since been deleted, but the city\\'s page shows that the woman still thinks the shooting was'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:32.798788Z",
     "start_time": "2021-05-14T03:44:32.793833Z"
    }
   },
   "outputs": [],
   "source": [
    "inp_text = \"How are you my friend? I am here to chat with you. I like your shirt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:34.968172Z",
     "start_time": "2021-05-14T03:44:34.901945Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n",
       "array([[ 2437,   389,   345,   616,  1545,    30,   314,   716,   994,\n",
       "          284,  8537,   351,   345,    13,   314,   588,   534, 10147]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = tf.convert_to_tensor(\n",
    "            np.stack(\n",
    "                [enc.encode(inp_text)]),\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:40.168449Z",
     "start_time": "2021-05-14T03:44:39.998654Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, _, _ = gpt2_loaded(inp, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:44:44.254041Z",
     "start_time": "2021-05-14T03:44:44.241445Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' to you doing friend?\"\\n\\'m your to help with you.\\n am to smile'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(np.argmax(predictions[0,:-1].numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:45:35.391634Z",
     "start_time": "2021-05-14T03:45:06.724412Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=inp,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-14T03:45:35.397107Z",
     "start_time": "2021-05-14T03:45:35.393161Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How are you my friend? I am here to chat with you. I like your shirt, you are pretty cool, I\\'d love to see your bra.\"\\n\\nI smile back. No, sorry my face is pale and the smile hurts, I thought I might not be able to smile anymore, but… I guess I did, I\\'m afraid. I do want to see you again though, I want you to have that good feeling inside you that\\'s waiting to pop and make me want to hug you as we continue talking, maybe one evening I\\'ll ask you to hang with me at the gym. Maybe in person and maybe I\\'ll even take you shopping later just to show you how much I care. It\\'s all up in the air, really, but I\\'m sure I can do it.\\n\\nI sit down.\\n\\n\"It does me good to see you smiling, I like how I like that, let\\'s get to it.\"\\n\\nWe head to the gym.\\n\\nI\\'m working out a whole lot. As long as I keep my'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Convert ckpt to model file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:55:30.153405Z",
     "start_time": "2021-06-01T04:55:28.945116Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:55:33.037751Z",
     "start_time": "2021-06-01T04:55:31.844911Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = model_tf2.create_GPT2_model(model_tf2.HPARAMS[\"355M\"], train_wte_weight_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:55:34.042716Z",
     "start_time": "2021-06-01T04:55:33.990205Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wte (SharedEmbeddings)       multiple                  51463168  \n",
      "_________________________________________________________________\n",
      "wpe (Embedding)              multiple                  1048576   \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 51,463,168\n",
      "Non-trainable params: 303,360,000\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:56:48.303147Z",
     "start_time": "2021-06-01T04:56:48.299051Z"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_path = \"../checkpoint/stocky_2010-2020_355M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:56:50.492312Z",
     "start_time": "2021-06-01T04:56:49.523155Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4b1a8a89d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt = tf.train.Checkpoint(gpt2=gpt2)\n",
    "ckpt.restore(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T22:38:00.781569Z",
     "start_time": "2021-05-22T22:37:59.397543Z"
    }
   },
   "outputs": [],
   "source": [
    "# gpt2.save_weights(\n",
    "#     \"../models/stocky_2010-2020_355M/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T04:56:53.828496Z",
     "start_time": "2021-06-01T04:56:53.818555Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 1 trainable variables.\n",
      "gpt2_tf2/wte/weight:0 (50257, 1024) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} trainable variables.\".format(\n",
    "    len(gpt2.trainable_variables)))\n",
    "for v in gpt2.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T22:29:43.985922Z",
     "start_time": "2021-05-22T22:29:43.968855Z"
    }
   },
   "outputs": [],
   "source": [
    "last_layer_weight = None\n",
    "for v in gpt2.trainable_variables:\n",
    "    if v.name == 'gpt2_tf2/wte/weight:0':\n",
    "        last_layer_weight = v\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-22T22:30:44.580749Z",
     "start_time": "2021-05-22T22:30:44.551661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'gpt2_tf2/wte/weight:0' shape=(50257, 1024) dtype=float32, numpy=\n",
       "array([[-0.02340584, -0.01267407, -0.01655046, ..., -0.02590171,\n",
       "        -0.17037265,  0.02376372],\n",
       "       [-0.01937613,  0.06209204, -0.02496111, ..., -0.01642366,\n",
       "        -0.11298505,  0.04505249],\n",
       "       [ 0.04571723,  0.05569463, -0.02517636, ..., -0.0775172 ,\n",
       "        -0.16430952,  0.02330942],\n",
       "       ...,\n",
       "       [-0.13947996, -0.10123608,  0.03851225, ..., -0.1226564 ,\n",
       "         0.03278604,  0.01880356],\n",
       "       [-0.25841242, -0.055912  ,  0.01844013, ..., -0.02956751,\n",
       "         0.00672574, -0.02828892],\n",
       "       [-0.19863187, -0.04811814, -0.02232354, ..., -0.0115201 ,\n",
       "         0.03277342,  0.02768158]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_layer_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.3] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
