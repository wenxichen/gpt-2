{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:12:31.168629Z",
     "start_time": "2021-04-17T07:12:31.163885Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:12:32.574075Z",
     "start_time": "2021-04-17T07:12:32.569247Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:12:37.848191Z",
     "start_time": "2021-04-17T07:12:32.999060Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:12:37.932377Z",
     "start_time": "2021-04-17T07:12:37.851045Z"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ROOT = './checkpoint'\n",
    "SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:00.021657Z",
     "start_time": "2021-04-17T07:12:59.278995Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = model_tf2.GPT2(model_tf2.HPARAMS['355M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:02.881643Z",
     "start_time": "2021-04-17T07:13:02.877203Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))\n",
    "# mask = model_tf2.create_look_ahead_mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:06.277046Z",
     "start_time": "2021-04-17T07:13:04.045873Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:09.649108Z",
     "start_time": "2021-04-17T07:13:09.606373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  52511744  \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "_________________________________________________________________\n",
      "look_up (LookUp)             multiple                  51463168  \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 354,823,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:13.962976Z",
     "start_time": "2021-04-17T07:13:13.863485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 292 trainable variables.\n",
      "gpt2_tf2/wpe:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/wte:0 (50257, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/beta:0 (1024,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} trainable variables.\".format(\n",
    "    len(gpt2.trainable_variables)))\n",
    "for v in gpt2.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from TF1 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:28.549417Z",
     "start_time": "2021-04-17T07:13:28.545015Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_directory = \"../models/355M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:45.591704Z",
     "start_time": "2021-04-17T07:13:32.428741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h0/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h0/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h0/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h0/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h1/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h1/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h1/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h1/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h1/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h10/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h10/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h10/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h10/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h10/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h11/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h11/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h11/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h11/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h11/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h12/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h12/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h12/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h12/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h12/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h12/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h13/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h13/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h13/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h13/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h13/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h13/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h14/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h14/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h14/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h14/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h14/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h14/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h15/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h15/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h15/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h15/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h15/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h15/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h16/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h16/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h16/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h16/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h16/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h16/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h17/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h17/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h17/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h17/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h17/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h17/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h18/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h18/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h18/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h18/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h18/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h18/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h19/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h19/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h19/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h19/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h19/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h19/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_proj/w with shape [1, 4096, 1024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h2/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h2/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h2/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h2/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h20/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h20/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h20/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h20/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h20/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h20/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h21/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h21/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h21/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h21/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h21/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h21/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h22/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h22/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h22/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h22/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h22/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h22/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h23/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h23/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h23/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h23/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h23/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h23/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h3/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h3/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h3/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h3/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h3/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h4/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h4/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h4/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h4/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h4/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h5/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h5/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h5/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h5/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h5/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h6/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h6/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h6/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h6/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h6/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h7/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h7/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h7/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h7/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h7/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h8/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h8/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h8/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h8/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h8/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h9/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h9/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h9/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h9/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 1024, 4096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/ln_f/b with shape [1024]\n",
      "Loading TF weight model/ln_f/g with shape [1024]\n",
      "Loading TF weight model/wpe with shape [1024, 1024]\n",
      "Loading TF weight model/wte with shape [50257, 1024]\n",
      "292 vars loaded from ckpt ../models/355M\n"
     ]
    }
   ],
   "source": [
    "ckpt_vars = tf.train.list_variables(ckpt_directory)\n",
    "names = []\n",
    "tensors = []\n",
    "\n",
    "for name, shape in ckpt_vars:\n",
    "    print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    tensor = tf.train.load_variable(ckpt_directory, name)\n",
    "    names.append(str(name[6:].split(\"/\")))\n",
    "    tensors.append(tensor)\n",
    "assert len(names) == len(tensors)\n",
    "print(\"{} vars loaded from ckpt {}\".format(len(ckpt_vars), ckpt_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:54.368873Z",
     "start_time": "2021-04-17T07:13:54.363632Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_vmap = dict(zip(names, tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:55.432131Z",
     "start_time": "2021-04-17T07:13:55.427881Z"
    }
   },
   "outputs": [],
   "source": [
    "vname_mapping = {\"kernel\": \"w\", \"bias\": \"b\", \"gamma\": \"g\", \"beta\": \"b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:56.740418Z",
     "start_time": "2021-04-17T07:13:56.148646Z"
    }
   },
   "outputs": [],
   "source": [
    "for v in gpt2.trainable_variables:\n",
    "    tf2_vname = v.name[9:-2].split(\"/\")\n",
    "    if tf2_vname[0] == \"decoder\":\n",
    "        tf2_vname = tf2_vname[1:]\n",
    "    if tf2_vname[-1] in vname_mapping:\n",
    "        tf2_vname[-1] = vname_mapping[tf2_vname[-1]]\n",
    "    tf2_vvalue = np.squeeze(ckpt_vmap[str(tf2_vname)])\n",
    "    assert v.shape == tf2_vvalue.shape, \\\n",
    "        \"{} has different shape: gpt2_tf2 {} vs gpt2_tf1 {}\" \\\n",
    "        .format(v.name, str(v.shape), str(tf2_vvalue.shape))\n",
    "    v.assign(tf2_vvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:08.909567Z",
     "start_time": "2021-04-17T07:14:08.806159Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"355M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:11.220028Z",
     "start_time": "2021-04-17T07:14:11.209832Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:42.080562Z",
     "start_time": "2021-04-17T07:14:13.502955Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:47.924381Z",
     "start_time": "2021-04-17T07:14:47.915264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we be friends? How do you make someone fall in love, and do you have to be a monster to get someone to fall in love?<|endoftext|>Saskatoon police officers are appealing for help finding a young man who left his girlfriend\\'s home with her gun tucked into her purse before she killed herself.\\n\\nBarek Hulak and his girlfriend, 20-year-old Melissa Marie Hulak, were seen leaving their home in the 12500 block of West 37th Street at around 2:30 a.m. Tuesday. Police say they called 911 in the hours following the attack but did not immediately receive an answer.\\n\\nA video of the 911 call shows Hulak walking toward the front door, putting her phone into her hand, and walking back into the home. Police have called her a \"preppy\" and \"caring\" girl.\\n\\nHulak had texted Hulak and her boyfriend, saying she couldn\\'t handle being a mother or being apart from her'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:15:43.286964Z",
     "start_time": "2021-04-17T07:15:39.488784Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2.save_weights(\"../models/355M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:15:43.295048Z",
     "start_time": "2021-04-17T07:15:43.290189Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:11.566951Z",
     "start_time": "2021-04-17T07:16:11.435554Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded = model_tf2.GPT2(model_tf2.HPARAMS['355M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:13.383359Z",
     "start_time": "2021-04-17T07:16:13.378398Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:30.106597Z",
     "start_time": "2021-04-17T07:16:29.686598Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2_loaded(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:38.187242Z",
     "start_time": "2021-04-17T07:16:37.058226Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded.load_weights(\"../models/355M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:39.852024Z",
     "start_time": "2021-04-17T07:16:39.819604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      multiple                  52511744  \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "_________________________________________________________________\n",
      "look_up_2 (LookUp)           multiple                  51463168  \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 354,823,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:48.283151Z",
     "start_time": "2021-04-17T07:16:48.204472Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"355M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:16:49.245385Z",
     "start_time": "2021-04-17T07:16:49.239441Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:17:18.218294Z",
     "start_time": "2021-04-17T07:16:49.975639Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:17:23.189615Z",
     "start_time": "2021-04-17T07:17:23.181502Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can we be friends? What are the odds this thing will work, let alone this many different ways to get them to come back? It's still a mystery to me... I don't know this girl at all: her name is Lisa, and she has the longest head, but as far as I know she hasn't had the luck of some of the other girl who have gotten them to return. But, let's face the fact that every once in awhile one of them manages to get me to come up with something, and I've tried to keep that up even as I find myself thinking a lot about what I'm going to say. It's just as true here, the best way to do it is to ask your friends questions, make them your friends, and then find out if they understand you without trying to change who they are, and just like me you'll never know unless you ask for their opinion, I think it may be time that we try asking them to come back! They have been kind\""
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.3] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
