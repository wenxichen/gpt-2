{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:20.633240Z",
     "start_time": "2021-04-23T07:59:19.202900Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:21.068119Z",
     "start_time": "2021-04-23T07:59:21.063843Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:21.899775Z",
     "start_time": "2021-04-23T07:59:21.423167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:22.337185Z",
     "start_time": "2021-04-23T07:59:22.332702Z"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ROOT = './checkpoint'\n",
    "SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:37.255225Z",
     "start_time": "2021-04-23T07:59:36.992027Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = model_tf2.GPT2(model_tf2.HPARAMS['117M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:41.966931Z",
     "start_time": "2021-04-23T07:59:41.962031Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))\n",
    "# mask = model_tf2.create_look_ahead_mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T07:59:42.960594Z",
     "start_time": "2021-04-23T07:59:42.628735Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:09.649108Z",
     "start_time": "2021-04-17T07:13:09.606373Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  52511744  \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  302311424 \n",
      "_________________________________________________________________\n",
      "look_up (LookUp)             multiple                  51463168  \n",
      "=================================================================\n",
      "Total params: 354,823,168\n",
      "Trainable params: 354,823,168\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:13.962976Z",
     "start_time": "2021-04-17T07:13:13.863485Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 292 trainable variables.\n",
      "gpt2_tf2/wpe:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/wte:0 (50257, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h12/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h13/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h14/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h15/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h16/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h17/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h18/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h19/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h20/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h21/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h22/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/kernel:0 (1024, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_attn/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/kernel:0 (1024, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/attn/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/kernel:0 (1024, 4096) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_fc/bias:0 (4096,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/kernel:0 (4096, 1024) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/mlp/c_proj/bias:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_1/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h23/ln_2/beta:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/gamma:0 (1024,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/beta:0 (1024,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} trainable variables.\".format(\n",
    "    len(gpt2.trainable_variables)))\n",
    "for v in gpt2.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from TF1 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:28.549417Z",
     "start_time": "2021-04-17T07:13:28.545015Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_directory = \"../models/355M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:45.591704Z",
     "start_time": "2021-04-17T07:13:32.428741Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h0/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h0/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h0/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h0/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h0/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h1/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h1/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h1/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h1/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h1/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h1/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h10/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h10/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h10/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h10/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h10/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h10/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h11/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h11/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h11/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h11/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h11/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h11/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h12/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h12/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h12/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h12/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h12/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h12/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h12/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h12/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h13/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h13/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h13/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h13/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h13/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h13/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h13/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h13/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h14/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h14/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h14/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h14/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h14/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h14/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h14/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h14/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h15/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h15/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h15/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h15/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h15/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h15/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h15/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h15/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h16/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h16/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h16/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h16/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h16/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h16/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h16/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h16/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h17/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h17/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h17/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h17/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h17/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h17/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h17/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h17/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h18/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h18/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h18/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h18/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h18/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h18/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h18/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h18/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h19/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h19/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h19/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h19/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h19/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h19/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h19/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h19/mlp/c_proj/w with shape [1, 4096, 1024]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h2/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h2/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h2/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h2/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h2/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h2/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h20/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h20/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h20/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h20/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h20/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h20/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h20/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h20/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h21/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h21/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h21/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h21/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h21/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h21/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h21/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h21/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h22/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h22/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h22/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h22/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h22/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h22/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h22/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h22/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h23/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h23/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h23/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h23/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h23/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h23/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h23/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h23/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h3/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h3/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h3/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h3/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h3/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h3/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h4/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h4/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h4/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h4/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h4/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h4/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h5/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h5/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h5/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h5/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h5/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h5/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h6/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h6/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h6/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h6/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h6/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h6/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h7/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h7/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h7/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h7/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h7/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h7/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h8/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h8/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h8/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h8/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h8/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 1024, 4096]\n",
      "Loading TF weight model/h8/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/h9/attn/c_attn/b with shape [3072]\n",
      "Loading TF weight model/h9/attn/c_attn/w with shape [1, 1024, 3072]\n",
      "Loading TF weight model/h9/attn/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/attn/c_proj/w with shape [1, 1024, 1024]\n",
      "Loading TF weight model/h9/ln_1/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_1/g with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/b with shape [1024]\n",
      "Loading TF weight model/h9/ln_2/g with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_fc/b with shape [4096]\n",
      "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 1024, 4096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h9/mlp/c_proj/b with shape [1024]\n",
      "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 4096, 1024]\n",
      "Loading TF weight model/ln_f/b with shape [1024]\n",
      "Loading TF weight model/ln_f/g with shape [1024]\n",
      "Loading TF weight model/wpe with shape [1024, 1024]\n",
      "Loading TF weight model/wte with shape [50257, 1024]\n",
      "292 vars loaded from ckpt ../models/355M\n"
     ]
    }
   ],
   "source": [
    "ckpt_vars = tf.train.list_variables(ckpt_directory)\n",
    "names = []\n",
    "tensors = []\n",
    "\n",
    "for name, shape in ckpt_vars:\n",
    "    print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    tensor = tf.train.load_variable(ckpt_directory, name)\n",
    "    names.append(str(name[6:].split(\"/\")))\n",
    "    tensors.append(tensor)\n",
    "assert len(names) == len(tensors)\n",
    "print(\"{} vars loaded from ckpt {}\".format(len(ckpt_vars), ckpt_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:54.368873Z",
     "start_time": "2021-04-17T07:13:54.363632Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_vmap = dict(zip(names, tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:55.432131Z",
     "start_time": "2021-04-17T07:13:55.427881Z"
    }
   },
   "outputs": [],
   "source": [
    "vname_mapping = {\"kernel\": \"w\", \"bias\": \"b\", \"gamma\": \"g\", \"beta\": \"b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:13:56.740418Z",
     "start_time": "2021-04-17T07:13:56.148646Z"
    }
   },
   "outputs": [],
   "source": [
    "for v in gpt2.trainable_variables:\n",
    "    tf2_vname = v.name[9:-2].split(\"/\")\n",
    "    if tf2_vname[0] == \"decoder\":\n",
    "        tf2_vname = tf2_vname[1:]\n",
    "    if tf2_vname[-1] in vname_mapping:\n",
    "        tf2_vname[-1] = vname_mapping[tf2_vname[-1]]\n",
    "    tf2_vvalue = np.squeeze(ckpt_vmap[str(tf2_vname)])\n",
    "    assert v.shape == tf2_vvalue.shape, \\\n",
    "        \"{} has different shape: gpt2_tf2 {} vs gpt2_tf1 {}\" \\\n",
    "        .format(v.name, str(v.shape), str(tf2_vvalue.shape))\n",
    "    v.assign(tf2_vvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:08.909567Z",
     "start_time": "2021-04-17T07:14:08.806159Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"355M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:11.220028Z",
     "start_time": "2021-04-17T07:14:11.209832Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:42.080562Z",
     "start_time": "2021-04-17T07:14:13.502955Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:14:47.924381Z",
     "start_time": "2021-04-17T07:14:47.915264Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we be friends? How do you make someone fall in love, and do you have to be a monster to get someone to fall in love?<|endoftext|>Saskatoon police officers are appealing for help finding a young man who left his girlfriend\\'s home with her gun tucked into her purse before she killed herself.\\n\\nBarek Hulak and his girlfriend, 20-year-old Melissa Marie Hulak, were seen leaving their home in the 12500 block of West 37th Street at around 2:30 a.m. Tuesday. Police say they called 911 in the hours following the attack but did not immediately receive an answer.\\n\\nA video of the 911 call shows Hulak walking toward the front door, putting her phone into her hand, and walking back into the home. Police have called her a \"preppy\" and \"caring\" girl.\\n\\nHulak had texted Hulak and her boyfriend, saying she couldn\\'t handle being a mother or being apart from her'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:15:43.286964Z",
     "start_time": "2021-04-17T07:15:39.488784Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2.save_weights(\"../models/355M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-17T07:15:43.295048Z",
     "start_time": "2021-04-17T07:15:43.290189Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:01.658441Z",
     "start_time": "2021-04-23T08:00:01.581861Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded = model_tf2.GPT2(model_tf2.HPARAMS['117M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:02.916980Z",
     "start_time": "2021-04-23T08:00:02.912008Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:03.676913Z",
     "start_time": "2021-04-23T08:00:03.458022Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2_loaded(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:15.140590Z",
     "start_time": "2021-04-23T08:00:09.634861Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded.load_weights(\"../models/117M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:15.158682Z",
     "start_time": "2021-04-23T08:00:15.143482Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  39383808  \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  85056000  \n",
      "_________________________________________________________________\n",
      "look_up_1 (LookUp)           multiple                  38597376  \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:00:22.294028Z",
     "start_time": "2021-04-23T08:00:22.216391Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"117M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:11:11.921346Z",
     "start_time": "2021-04-23T08:11:11.915089Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:11:26.407151Z",
     "start_time": "2021-04-23T08:11:12.249201Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:11:26.411735Z",
     "start_time": "2021-04-23T08:11:26.408429Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Can we be friends?\\n\\n\\nYou may use this topic\\n\\nCheck out my website's the best way to learn.\\n\\nA lot has to do\\n\\nWant to make a life change? The Completely do.\\n\\nHow to become a better man!\\n\\nJust get a job to earn a living now.\\n\\nYour life's only to take you on.\\n\\nDo you want to be a better man?\\n\\nIf you don't want to lose that you're a better than ever before\\n\\nGo to the right people now.\\n\\nFind the help right now.\\n\\nDo you want to go to a job for help?\\n\\nA lot happens before we're ready to go.\\n\\nDo you want to stay on what you are now\\n\\nYou are ready.\\n\\nDid you know the most important thing to know from being a better man (and a better man than you) is...\\n\\nNot getting involved in politics, becoming a better than\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:54.635915Z",
     "start_time": "2021-04-23T08:08:54.631843Z"
    }
   },
   "outputs": [],
   "source": [
    "inp_text = \"How are you my friend? I am here to chat with you. I like your shirt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:55.339580Z",
     "start_time": "2021-04-23T08:08:55.331639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n",
       "array([[ 2437,   389,   345,   616,  1545,    30,   314,   716,   994,\n",
       "          284,  8537,   351,   345,    13,   314,   588,   534, 10147]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = tf.convert_to_tensor(\n",
    "            np.stack(\n",
    "                [enc.encode(inp_text)]),\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:57.988509Z",
     "start_time": "2021-04-23T08:08:57.889689Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, _, _ = gpt2_loaded(inp, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:58.383572Z",
     "start_time": "2021-04-23T08:08:58.375513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',/._ of\\n,,tic the the\\n won. is in name'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(np.argmax(predictions[0,:-1].numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:10:28.646857Z",
     "start_time": "2021-04-23T08:10:14.409998Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=inp,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:10:28.652348Z",
     "start_time": "2021-04-23T08:10:28.648300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How are you my friend? I am here to chat with you. I like your shirton\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDont'\\n\\n\\n\\nyou can do better in the best way to\\n\\n\\ntell me\\n\\n\\nI could hear ya\\n\\nMy name is\\n\\nWe can tell you how i mean\\n\\nYou get what I mean. I like doing\\n\\nI can't understand\\n\\nYou make me? What i'm say\\n\\nI'm not doing well,\\n\\n\\nI'm not in my mouth to\\n\\n\\nI'm not\\n\\n\\nOh\\n\\n\\nyou can I have\\n\\n\\n\\nI have\\n\\n\\n\\n\\nyou\\n\\n\\n\\nI like a\\n\\n\\n\\n\\n\\n\\nI've been\\n\\n\\n\\nwhat you\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI'm\\n\\n\\n\\n\\n\\nyou\\n\\n\\n\\nwhat you can\\n\\n\\n\\n\\nI'm of\\n\\n\\n\\n\\nyou\\n\\nyou\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.3] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
