{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:35.959569Z",
     "start_time": "2021-05-12T07:32:34.663207Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:35.963974Z",
     "start_time": "2021-05-12T07:32:35.961459Z"
    }
   },
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:36.639355Z",
     "start_time": "2021-05-12T07:32:35.965733Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/device:GPU:0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:36.740015Z",
     "start_time": "2021-05-12T07:32:36.640574Z"
    }
   },
   "outputs": [],
   "source": [
    "CHECKPOINT_ROOT = './checkpoint'\n",
    "SEQ_LEN = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:37.085096Z",
     "start_time": "2021-05-12T07:32:36.742149Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2 = model_tf2.GPT2(model_tf2.HPARAMS['117M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:37.089304Z",
     "start_time": "2021-05-12T07:32:37.086418Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))\n",
    "# mask = model_tf2.create_look_ahead_mask(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:37.570902Z",
     "start_time": "2021-05-12T07:32:37.092467Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:38.276875Z",
     "start_time": "2021-05-12T07:32:38.252809Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wte (SharedEmbeddings)       multiple                  38597376  \n",
      "_________________________________________________________________\n",
      "wpe (Embedding)              multiple                  786432    \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  85056000  \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:40.863505Z",
     "start_time": "2021-05-12T07:32:40.807029Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 148 trainable variables.\n",
      "gpt2_tf2/wte/weight:0 (50257, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/wpe/embeddings:0 (1024, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h0/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h1/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h2/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h3/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h4/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h5/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h6/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h7/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h8/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h9/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h10/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/kernel:0 (768, 2304) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_attn/bias:0 (2304,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/kernel:0 (768, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/attn/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/kernel:0 (768, 3072) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_fc/bias:0 (3072,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/kernel:0 (3072, 768) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/mlp/c_proj/bias:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_1/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/h11/ln_2/beta:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/gamma:0 (768,) <dtype: 'float32'>\n",
      "gpt2_tf2/decoder/ln_f/beta:0 (768,) <dtype: 'float32'>\n"
     ]
    }
   ],
   "source": [
    "print(\"Total {} trainable variables.\".format(\n",
    "    len(gpt2.trainable_variables)))\n",
    "for v in gpt2.trainable_variables:\n",
    "    print(v.name, v.shape, v.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load from TF1 Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:48.150403Z",
     "start_time": "2021-05-12T07:32:48.146081Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_directory = \"../models/117M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:55.539326Z",
     "start_time": "2021-05-12T07:32:51.397517Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TF weight model/h0/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h0/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h0/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h0/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h0/ln_1/b with shape [768]\n",
      "Loading TF weight model/h0/ln_1/g with shape [768]\n",
      "Loading TF weight model/h0/ln_2/b with shape [768]\n",
      "Loading TF weight model/h0/ln_2/g with shape [768]\n",
      "Loading TF weight model/h0/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h0/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h0/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h0/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h1/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h1/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h1/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h1/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h1/ln_1/b with shape [768]\n",
      "Loading TF weight model/h1/ln_1/g with shape [768]\n",
      "Loading TF weight model/h1/ln_2/b with shape [768]\n",
      "Loading TF weight model/h1/ln_2/g with shape [768]\n",
      "Loading TF weight model/h1/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h1/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h1/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h1/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h10/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h10/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h10/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h10/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h10/ln_1/b with shape [768]\n",
      "Loading TF weight model/h10/ln_1/g with shape [768]\n",
      "Loading TF weight model/h10/ln_2/b with shape [768]\n",
      "Loading TF weight model/h10/ln_2/g with shape [768]\n",
      "Loading TF weight model/h10/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h10/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h10/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h10/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h11/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h11/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h11/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h11/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h11/ln_1/b with shape [768]\n",
      "Loading TF weight model/h11/ln_1/g with shape [768]\n",
      "Loading TF weight model/h11/ln_2/b with shape [768]\n",
      "Loading TF weight model/h11/ln_2/g with shape [768]\n",
      "Loading TF weight model/h11/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h11/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h11/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h11/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h2/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h2/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h2/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h2/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h2/ln_1/b with shape [768]\n",
      "Loading TF weight model/h2/ln_1/g with shape [768]\n",
      "Loading TF weight model/h2/ln_2/b with shape [768]\n",
      "Loading TF weight model/h2/ln_2/g with shape [768]\n",
      "Loading TF weight model/h2/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h2/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h2/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h2/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h3/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h3/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h3/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h3/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h3/ln_1/b with shape [768]\n",
      "Loading TF weight model/h3/ln_1/g with shape [768]\n",
      "Loading TF weight model/h3/ln_2/b with shape [768]\n",
      "Loading TF weight model/h3/ln_2/g with shape [768]\n",
      "Loading TF weight model/h3/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h3/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h3/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h3/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h4/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h4/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h4/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h4/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h4/ln_1/b with shape [768]\n",
      "Loading TF weight model/h4/ln_1/g with shape [768]\n",
      "Loading TF weight model/h4/ln_2/b with shape [768]\n",
      "Loading TF weight model/h4/ln_2/g with shape [768]\n",
      "Loading TF weight model/h4/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h4/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h4/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h4/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h5/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h5/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h5/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h5/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h5/ln_1/b with shape [768]\n",
      "Loading TF weight model/h5/ln_1/g with shape [768]\n",
      "Loading TF weight model/h5/ln_2/b with shape [768]\n",
      "Loading TF weight model/h5/ln_2/g with shape [768]\n",
      "Loading TF weight model/h5/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h5/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h5/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h5/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h6/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h6/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h6/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h6/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h6/ln_1/b with shape [768]\n",
      "Loading TF weight model/h6/ln_1/g with shape [768]\n",
      "Loading TF weight model/h6/ln_2/b with shape [768]\n",
      "Loading TF weight model/h6/ln_2/g with shape [768]\n",
      "Loading TF weight model/h6/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h6/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h6/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h6/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h7/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h7/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h7/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h7/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h7/ln_1/b with shape [768]\n",
      "Loading TF weight model/h7/ln_1/g with shape [768]\n",
      "Loading TF weight model/h7/ln_2/b with shape [768]\n",
      "Loading TF weight model/h7/ln_2/g with shape [768]\n",
      "Loading TF weight model/h7/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h7/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h7/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h7/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h8/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h8/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h8/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h8/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h8/ln_1/b with shape [768]\n",
      "Loading TF weight model/h8/ln_1/g with shape [768]\n",
      "Loading TF weight model/h8/ln_2/b with shape [768]\n",
      "Loading TF weight model/h8/ln_2/g with shape [768]\n",
      "Loading TF weight model/h8/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h8/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h8/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h8/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/h9/attn/c_attn/b with shape [2304]\n",
      "Loading TF weight model/h9/attn/c_attn/w with shape [1, 768, 2304]\n",
      "Loading TF weight model/h9/attn/c_proj/b with shape [768]\n",
      "Loading TF weight model/h9/attn/c_proj/w with shape [1, 768, 768]\n",
      "Loading TF weight model/h9/ln_1/b with shape [768]\n",
      "Loading TF weight model/h9/ln_1/g with shape [768]\n",
      "Loading TF weight model/h9/ln_2/b with shape [768]\n",
      "Loading TF weight model/h9/ln_2/g with shape [768]\n",
      "Loading TF weight model/h9/mlp/c_fc/b with shape [3072]\n",
      "Loading TF weight model/h9/mlp/c_fc/w with shape [1, 768, 3072]\n",
      "Loading TF weight model/h9/mlp/c_proj/b with shape [768]\n",
      "Loading TF weight model/h9/mlp/c_proj/w with shape [1, 3072, 768]\n",
      "Loading TF weight model/ln_f/b with shape [768]\n",
      "Loading TF weight model/ln_f/g with shape [768]\n",
      "Loading TF weight model/wpe with shape [1024, 768]\n",
      "Loading TF weight model/wte with shape [50257, 768]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148 vars loaded from ckpt ../models/117M\n"
     ]
    }
   ],
   "source": [
    "ckpt_vars = tf.train.list_variables(ckpt_directory)\n",
    "names = []\n",
    "tensors = []\n",
    "\n",
    "for name, shape in ckpt_vars:\n",
    "    print(\"Loading TF weight {} with shape {}\".format(name, shape))\n",
    "    tensor = tf.train.load_variable(ckpt_directory, name)\n",
    "    names.append(str(name[6:].split(\"/\")))\n",
    "    tensors.append(tensor)\n",
    "assert len(names) == len(tensors)\n",
    "print(\"{} vars loaded from ckpt {}\".format(len(ckpt_vars), ckpt_directory))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:58.278896Z",
     "start_time": "2021-05-12T07:32:58.274235Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt_vmap = dict(zip(names, tensors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:58.697606Z",
     "start_time": "2021-05-12T07:32:58.693023Z"
    }
   },
   "outputs": [],
   "source": [
    "vname_mapping = {\"kernel\": \"w\", \"bias\": \"b\", \"gamma\": \"g\", \"beta\": \"b\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:32:59.504947Z",
     "start_time": "2021-05-12T07:32:59.280208Z"
    }
   },
   "outputs": [],
   "source": [
    "for v in gpt2.trainable_variables:\n",
    "    tf2_vname = v.name[9:-2].split(\"/\")\n",
    "    if tf2_vname[0] == \"decoder\":\n",
    "        tf2_vname = tf2_vname[1:]\n",
    "    elif tf2_vname[0] == \"wte\" or tf2_vname[0] == \"wpe\":\n",
    "        tf2_vname = [tf2_vname[0]]\n",
    "    if tf2_vname[-1] in vname_mapping:\n",
    "        tf2_vname[-1] = vname_mapping[tf2_vname[-1]]\n",
    "    tf2_vvalue = np.squeeze(ckpt_vmap[str(tf2_vname)])\n",
    "    assert v.shape == tf2_vvalue.shape, \\\n",
    "        \"{} has different shape: gpt2_tf2 {} vs gpt2_tf1 {}\" \\\n",
    "        .format(v.name, str(v.shape), str(tf2_vvalue.shape))\n",
    "    v.assign(tf2_vvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:33:02.943699Z",
     "start_time": "2021-05-12T07:33:02.753379Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"117M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:33:03.212106Z",
     "start_time": "2021-05-12T07:33:03.205736Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:33:19.036023Z",
     "start_time": "2021-05-12T07:33:03.884964Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-12T07:33:19.041470Z",
     "start_time": "2021-05-12T07:33:19.037298Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we be friends? If not, why not? We just met once back in March. I\\'m glad I haven\\'t. Thank you.\"\\n\\nWith all that being said, I\\'m glad you\\'re here. I love you.\\n\\nHere\\'s hoping you enjoy everything coming your way, and thank you for everything that you did for the community. There\\'s no better way to enjoy all of our events, especially when we\\'re surrounded by great people with great things to do. We want to keep it on social media, and let you know you can join us online and let the world know how awesome your event was. Also, please keep up with the latest news.\\n\\nIf you\\'d like to see what we\\'re bringing to 2017, check out the official website here. (Thanks again to @Cindroz)<|endoftext|>I\\'m not entirely sure what to mean by this article. You should look it up for anything about the story, but it was just a quick overview of what kind of situation'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:45:53.058809Z",
     "start_time": "2021-05-08T06:45:50.393529Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2.save_weights(\"../models/117M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Load the saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:46:56.650766Z",
     "start_time": "2021-05-08T06:46:54.991611Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time, os, logging\n",
    "import sample_tf2, model_tf2, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:46:59.026599Z",
     "start_time": "2021-05-08T06:46:58.223982Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded = model_tf2.GPT2(model_tf2.HPARAMS['117M'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:46:59.821386Z",
     "start_time": "2021-05-08T06:46:59.816532Z"
    }
   },
   "outputs": [],
   "source": [
    "X = tf.convert_to_tensor(np.array([[35, 789], [98, 69]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:00.986456Z",
     "start_time": "2021-05-08T06:47:00.663492Z"
    }
   },
   "outputs": [],
   "source": [
    "logits, presents, _ = gpt2_loaded(X, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:02.132202Z",
     "start_time": "2021-05-08T06:47:01.717038Z"
    }
   },
   "outputs": [],
   "source": [
    "gpt2_loaded.load_weights(\"../models/117M_tf2/pretrained_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:03.400380Z",
     "start_time": "2021-05-08T06:47:03.375358Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"gpt2_tf2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "wte (SharedEmbeddings)       multiple                  38597376  \n",
      "_________________________________________________________________\n",
      "wpe (Embedding)              multiple                  786432    \n",
      "_________________________________________________________________\n",
      "decoder (Decoder)            multiple                  85056000  \n",
      "=================================================================\n",
      "Total params: 124,439,808\n",
      "Trainable params: 124,439,808\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "gpt2_loaded.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loaded gpt2_tf2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:08.686112Z",
     "start_time": "2021-05-08T06:47:08.453665Z"
    }
   },
   "outputs": [],
   "source": [
    "enc = encoder.get_encoder(\"117M\", \"../models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:09.380523Z",
     "start_time": "2021-05-08T06:47:09.374940Z"
    }
   },
   "outputs": [],
   "source": [
    "context = enc.encode(\"Can we be friends?\")\n",
    "context = tf.convert_to_tensor(context,dtype=tf.int32)\n",
    "context = tf.expand_dims(context, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:29.040287Z",
     "start_time": "2021-05-08T06:47:10.072985Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=context,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-08T06:47:29.066026Z",
     "start_time": "2021-05-08T06:47:29.044010Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Can we be friends?\\n\\n\\nI thought of my mother\\n\\nShe didn\\'t know she was dead.\\n\\n\\nThis wasn\\'t my first thing to do.\\n\\nWe went off together.\\n\\n\"We have a great plan.\\n\\n\\nDon\\'t let go\\n\\nI don\\'t let go and I don\\'t go\\n\\n\\nWe need to put that back on\\n\\n\\nShe had nothing left to lose.\\n\\nWe need to get it back on\\n\\nDon\\'t leave her alone.\\n\\n\\nIn some way, I am in good enough shape to go with you<|endoftext|>Sebastian Weidman at her usual blog. (AP Photo/The Washington Post)\\n\\nI was shocked and saddened at the thought of the loss of a former staffer who wrote about my struggles as a parent.\\n\\nHe said she died and I feel terrible I didn\\'t know him. Or that I shouldn\\'t have known. But there are other people who know him. Here\\'s one about me in'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:54.635915Z",
     "start_time": "2021-04-23T08:08:54.631843Z"
    }
   },
   "outputs": [],
   "source": [
    "inp_text = \"How are you my friend? I am here to chat with you. I like your shirt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:55.339580Z",
     "start_time": "2021-04-23T08:08:55.331639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 18), dtype=int32, numpy=\n",
       "array([[ 2437,   389,   345,   616,  1545,    30,   314,   716,   994,\n",
       "          284,  8537,   351,   345,    13,   314,   588,   534, 10147]],\n",
       "      dtype=int32)>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = tf.convert_to_tensor(\n",
    "            np.stack(\n",
    "                [enc.encode(inp_text)]),\n",
    "            dtype=tf.int32\n",
    "        )\n",
    "inp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:57.988509Z",
     "start_time": "2021-04-23T08:08:57.889689Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions, _, _ = gpt2_loaded(inp, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:08:58.383572Z",
     "start_time": "2021-04-23T08:08:58.375513Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "',/._ of\\n,,tic the the\\n won. is in name'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(np.argmax(predictions[0,:-1].numpy(), axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:10:28.646857Z",
     "start_time": "2021-04-23T08:10:14.409998Z"
    }
   },
   "outputs": [],
   "source": [
    "output = sample_tf2.sample_sequence(\n",
    "    gpt2_model=gpt2_loaded,\n",
    "    length=200,\n",
    "    context=inp,\n",
    "    top_p=0,\n",
    "    top_k=40,\n",
    "    batch_size=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-23T08:10:28.652348Z",
     "start_time": "2021-04-23T08:10:28.648300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"How are you my friend? I am here to chat with you. I like your shirton\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nDont'\\n\\n\\n\\nyou can do better in the best way to\\n\\n\\ntell me\\n\\n\\nI could hear ya\\n\\nMy name is\\n\\nWe can tell you how i mean\\n\\nYou get what I mean. I like doing\\n\\nI can't understand\\n\\nYou make me? What i'm say\\n\\nI'm not doing well,\\n\\n\\nI'm not in my mouth to\\n\\n\\nI'm not\\n\\n\\nOh\\n\\n\\nyou can I have\\n\\n\\n\\nI have\\n\\n\\n\\n\\nyou\\n\\n\\n\\nI like a\\n\\n\\n\\n\\n\\n\\nI've been\\n\\n\\n\\nwhat you\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI'm\\n\\n\\n\\n\\n\\nyou\\n\\n\\n\\nwhat you can\\n\\n\\n\\n\\nI'm of\\n\\n\\n\\n\\nyou\\n\\nyou\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enc.decode(output[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-2.3] *",
   "language": "python",
   "name": "conda-env-tensorflow-2.3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
